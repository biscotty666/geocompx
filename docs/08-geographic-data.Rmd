---
title: "Ch 8 Geographic data I/O"
---

```{r}
library(sf)
library(terra)
library(dplyr)
library(spData)
```

# File formats

| Name              | Extension            | Info                                                                                                                                                                                              | Type                             | Model          |
|:--------------|:--------------|:--------------|:--------------|:--------------|
| ESRI Shapefile    | .shp (the main file) | Popular format consisting of at least three files. No support for: files \> 2GB; mixed types; names \> 10 chars; cols \> 255.                                                                     | Vector                           | Partially open |
| GeoJSON           | .geojson             | Extends the JSON exchange format by including a subset of the simple feature representation; mostly used for storing coordinates in longitude and latitude; it is extended by the TopoJSON format | Vector                           | Open           |
| KML               | .kml                 | XML-based format for spatial visualization, developed for use with Google Earth. Zipped KML file forms the KMZ format.                                                                            | Vector                           | Open           |
| GPX               | .gpx                 | XML schema created for exchange of GPS data.                                                                                                                                                      | Vector                           | Open           |
| FlatGeobuf        | .fgb                 | Single file format allowing for quick reading and writing of vector data. Has streaming capabilities.                                                                                             | Vector                           | Open           |
| GeoTIFF           | .tif/.tiff           | Popular raster format. A TIFF file containing additional spatial metadata.                                                                                                                        | Raster                           | Open           |
| Arc ASCII         | .asc                 | Text format where the first six lines represent the raster header, followed by the raster cell values arranged in rows and columns.                                                               | Raster                           | Open           |
| SQLite/SpatiaLite | .sqlite              | Standalone relational database, SpatiaLite is the spatial extension of SQLite.                                                                                                                    | Vector and raster                | Open           |
| ESRI FileGDB      | .gdb                 | Spatial and nonspatial objects created by ArcGIS. Allows: multiple feature classes; topology. Limited support from GDAL.                                                                          | Vector and raster                | Proprietary    |
| GeoPackage        | .gpkg                | Lightweight database container based on SQLite allowing an easy and platform-independent exchange of geodata                                                                                      | Vector and (very limited) raster | Open           |

# Data input

## Vector data

The following commands show the first three drivers reported the computer’s GDAL installation (results can vary depending on the GDAL version installed) and a summary of their features. Note that the majority of drivers can write data, while only a dozen or so formats can efficiently represent raster data in addition to vector data (see `?st_drivers()` for details):

```{r}
sf_drivers <- st_drivers()
print.AsIs(head(sf_drivers, 5))
```

```{r}
summary(sf_drivers[-c(1:2)])
```

The first argument of read_sf() is dsn, which should be a text string or an object containing a single text string. The content of a text string could vary between different drivers. In most cases, as with the ESRI Shapefile (.shp) or the GeoPackage format (.gpkg), the dsn would be a file name. read_sf() guesses the driver based on the file extension, as illustrated for a .gpkg file below:

```{r}
f <- system.file("shapes/world.gpkg", 
                 package = "spData")
world <- read_sf(f)
```

The read_sf() function also allows for reading just parts of the file into RAM with two possible mechanisms. The first one is related to the query argument, which allows specifying what part of the data to read with the OGR SQL query text.

```{r}
tanzania <- read_sf(f,
                    query = '
                      SELECT * FROM world
                      WHERE name_long = "Tanzania"
                    '
)
```

```{r}
library(tmap)
tm_shape(tanzania) +
  tm_borders() +
  tm_fill()
```

> If you do not know the names of the available columns, a good approach is to just read one row of the data with 'SELECT \* FROM world WHERE FID = 1'. FID represents a feature ID – most often, it is a row number; however, its values depend on the used file format. For example, FID starts from 0 in ESRI Shapefile, from 1 in some other file formats, or can be even arbitrary.

The second mechanism uses the wkt_filter argument. This argument expects a well-known text representing a study area for which we want to extract the data. Let’s try it using a small example – we want to read polygons from our file that intersect with the buffer of 50,000 meters of Tanzania’s borders. To do it, we need to prepare our “filter” by (a) creating the buffer (Section 5.2.3), (b) converting the sf buffer object into an sfc geometry object with st_geometry(), and (c) translating geometries into their well-known text representation with st_as_text():

```{r}
tanzania_buf <- st_buffer(tanzania, 50000)
tanzania_buf_geom <- st_geometry(tanzania_buf)
tanzania_buf_wkt <- st_as_text(tanzania_buf_geom)
```

Now, we can apply this “filter” using the wkt_filter argument.

```{r}
tanzania_neigh <- read_sf(f, 
                          wkt_filter = tanzania_buf_wkt)
# tanzania_neigh[tanzania_neigh$iso_a2 == "CD", "name_long"] = "Democratic\nRepublic\nof the Congo"
tanzania_neigh[tanzania_neigh$iso_a2 == "CD", "name_long"] = "Democratic\nRepublic\nof the Congo"
```

```         
library(tmap)
tm1 = tm_shape(tanzania) +
  tm_polygons(lwd = 2) +
  tm_text(text = "name_long") + 
  tm_scalebar(c(0, 200, 400), position = c("left", "bottom")) +
  tm_title("A. query")
tanzania_neigh[tanzania_neigh$iso_a2 == "CD", "name_long"] = "Democratic\nRepublic\nof the Congo"
```

```         
tm_shape(tanzania_neigh) +
  tm_polygons() +
  tm_text(text = "name_long", 
          text.scale = tm_scale(auto.placement = FALSE, remove.overlap = FALSE), 
          size = "AREA", size.legend = tm_legend_hide(), root = 6) +
  tm_shape(tanzania_buf) +
  tm_polygons(col = "red", fill = "red", fill_alpha = 0.05) +
  tm_add_legend(type = "fill", labels = "50km buffer around Tanzania",
                col = "red", fill_alpha = 0.1, fill = "red")  +
  tm_scalebar(c(0, 200, 400), position = c("right", "bottom")) +
  tm_title("B. wkt_filter") +
  tm_layout(legend.position = c("LEFT", "BOTTOM"))
```

```         
tmap_arrange(tm1, tm2)
```

```{r}
tm2 <- tm_shape(tanzania_neigh) +
  tm_polygons() +
  tm_text(text = "name_long",
          size = "AREA",
          # size.legend = tm_legend_hide(),
          # text.scale = tm_scale(auto.placement = FALSE,
          #                       remove.overlap = FALSE),
          root = 6  # increases text size
          ) +
  tm_shape(tanzania_buf) +
  tm_polygons(col = "red",
              fill_alpha = 0.05,
              fill = "red") +
  tm_scalebar(breaks = c(0, 200, 400), 
              position = c("left", "bottom")) +
  tm_add_legend(labels = "50km buffer around Tanzania",
                col = "red", 
                fill = "red", fill_alpha = 0.1) +
  # tm_layout(legend.position = c("left", "bottom")) +
  tm_layout(legend.position = c("LEFT", "BOTTOM")) +
  tm_title("B. wkt_filter")

```

```{r}
tm1 <- tm_shape(tanzania) + 
  tm_polygons(lwd = 2) +
  tm_text(text = "name_long") +
  tm_scalebar(breaks = c(0, 200, 400),
              position = c("left", "bottom")) +
  tm_title("A. query")
```

```{r}
tmap_arrange(tm1, tm2)
```

Naturally, some options are specific to certain drivers.43 For example, think of coordinates stored in a spreadsheet format (.csv). To read in such files as spatial objects, we naturally have to specify the names of the columns (X and Y in our example below) representing the coordinates. We can do this with the help of the options parameter. To find out about possible options, please refer to the ‘Open Options’ section of the corresponding GDAL driver description. For the comma-separated value (csv) format, visit <https://gdal.org/drv_csv.html>.

```{r}
f_csv <- system.file("misc/cycle_hire_xy.csv",
                               package = "spData")
cycle_hire_xy <- read_sf(
  f_csv,
  options = c("X_POSSIBLE_NAMES=X", "Y_POSSIBLE_NAMES=Y")
)
```

The `world_wkt.csv` file has a column named WKT representing polygons of the world’s countries. We will again use the options parameter to indicate this.

```{r}
world_wkt <- read_sf(system.file("misc/world_wkt.csv",
                                 package = "spData"),
                     options = "GEOM_POSSIBLE_NAMES=WKT")
```

As a final example, we will show how read_sf() also reads KML files. A KML file stores geographic information in XML format - a data format for the creation of web pages and the transfer of data in an application-independent way (Nolan and Lang 2014). Here, we access a KML file from the web. This file contains more than one layer. st_layers() lists all available layers. We choose the first layer Placemarks and say so with the help of the layer parameter in read_sf().

```{r}
url <- "https://developers.google.com/kml/documentation/KML_Samples.kml"
download.file(url, "../data/KML_Samples.kml")
st_layers("../data/KML_Samples.kml") |> print.AsIs()
```

## Raster data

terra’s rast() command reads in a single layer when a file with just one layer is provided. It also works in case you want to read a multilayer file.

```{r}
raster_filepath = system.file("raster/srtm.tif", 
                              package = "spDataLarge")
single_layer = rast(raster_filepath)
```

```{r}
multilayer_filepath = system.file("raster/landsat.tif", 
                                  package = "spDataLarge")
multilayer_rast = rast(multilayer_filepath)
```

All of the previous examples read spatial information from files stored on your hard drive. However, GDAL also allows reading data directly from online resources, such as HTTP/HTTPS/FTP web resources. The only thing we need to do is to add a /vsicurl/ prefix before the path to the file. Let’s try it by connecting to the global monthly snow probability at 500 m resolution for the period 2000-2012. Snow probability for December is stored as a Cloud Optimized GeoTIFF (COG) file (see Section 8.2) at zenodo.org. To read an online file, we just need to provide its URL together with the /vsicurl/ prefix.

```{r}
url <- paste0("/vsicurl/https://zenodo.org/record/5774954/files/",
              "clm_snow.prob_esacci.dec_p.90_500m_s0..0cm_2000..2012_v2.0.tif")
snow <- rast(url)
snow
```

```{r}
rey <- data.frame(lon = -21.94, lat = 64.15)
snow_rey <- extract(snow, rey)
str(snow_rey)
```

```{r}
snow_rey |> print.AsIs()
```

# Data Output

## Vector data

```{r}
write_sf(obj = world, dsn = "../data/world.gpkg")
```

Add a new layer:

```{r}
write_sf(obj = world, 
         dsn = "../data/world.gpkg",
         layer = "second_layer")
```

Alternatively, you can use st_write() since it is equivalent to write_sf(). However, it has different defaults – it does not overwrite files (returns an error when you try to do it) and shows a short summary of the written file format and the object.

```{r}
st_write(obj = world, dsn = "../data/world2.gpkg", append = FALSE)
```

The `layer_options` argument could be also used for many different purposes. One of them is to write spatial data to a text file. This can be done by specifying `GEOMETRY` inside of `layer_options`. It could be either `AS_XY` for simple point datasets (it creates two new columns for coordinates) or `AS_WKT` for more complex spatial data (one new column is created which contains the well-known text representation of spatial objects).

```{r}
write_sf(cycle_hire_xy, "../data/cycle_hire_xy.csv",
         layer_options = "GEOMETRY=AS_XY")
write_sf(world_wkt, "../data/world_wkt.csv",
         layer_options = "GEOMETRY=AS_WKT")
```

## Raster data

```{r}
writeRaster(single_layer,
            filename = "../data/my_raster.tif",
            datatype = "INT2U",
            overwrite = TRUE)
```

GeoTIFF files are written in terra, by default, with the LZW compression gdal = c("COMPRESS=LZW"). To change or disable the compression, we need to modify this argument.

```{r}
writeRaster(x = single_layer,
            filename = "../data/my_raster.tif",
            gdal = c("COMPRESS=NONE"),
            overwrite = TRUE)
```

Save as Cloud Optimized GeoTIFF

```{r}
writeRaster(x = single_layer,
            filename = "../data/my_raster.tif",
            filetype = "COG",
            overwrite = TRUE)
```

# Geoportals

-   [Data.gov](https://catalog.data.gov/dataset?metadata_type=geospatial)
-   [GEOSS portal](https://www.geoportal.org/)
-   [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu/)
-   [SEDAC](https://sedac.ciesin.columbia.edu/) (NASA)
-   [INSPIRE geoportal](http://inspire-geoportal.ec.europa.eu/) (EU)
-   [EarthExplorer](#0) (USGS)
-   [Copernicus APIs](#0)
-   [pangaea.de](#0) Permafrost Region Pond and Lake Database

```{r}
url <- "https://hs.pangaea.de/Maps/PeRL/PeRL_permafrost_landscapes.zip"
download.file(url = url,
              destfile = "../data/PeRL_permafrost_landscapes.zip",
              mode = "wb")
unzip("../data/PeRL_permafrost_landscapes.zip", exdir = "../data")
canada_perma_land <- read_sf(
  "../data/PeRL_permafrost_landscapes/canada_perma_land.shp"
)
```

# Geographic data packages

## Sources

| Package       | Description                                                                                                     |
|:-------------------|:---------------------------------------------------|
| climateR      | Access over 100,000k gridded climate and landscape datasets from over 2,000 data providers by area of interest. |
| elevatr       | Access point and raster elevation data from various sources.                                                    |
| FedData       | Datasets maintained by the US Federal government, including elevation and land cover.                           |
| geodata       | Download and import imports administrative, elevation, WorldClim data.                                          |
| osmdata       | Download and import small OpenStreetMap datasets.                                                               |
| osmextract    | Download and import large OpenStreetMap datasets.                                                               |
| rnaturalearth | Access to Natural Earth vector and raster data.                                                                 |
| rnoaa         | Imports National Oceanic and Atmospheric Administration (NOAA) climate data.                                    |

a large number of R packages exist to obtain various socio-demographic data

-   **tidycensus** and **tigris** (USA)
-   **cancensus** (Canada),
-   **eurostat** and **giscoR** (European Union)
-   **idbr** (international databases)

Several R packages exist giving access to spatial data for various regions and countries, such as

-   **bcdata** (Province of British Columbia)
-   **geobr** (Brazil)
-   **RCzechia** (Czech Republic)
-   **rgugik** (Poland).

Country borders:

-   **rnaturalearth**
-   **geodata**
-   **giscoR**
-   **rgeoboundaries**

```{r}
library(rnaturalearth)
usa_sf <- ne_countries(country = "United States of America",
                       returnclass = "sf")
```

Global monthly precipitation with **geodata**

```{r}
library(geodata)
worldclim_prec <- worldclim_global("prec",
                                   res = 10,
                                   path = tempdir())
class(worldclim_prec)
```

Features like parks from **osm_data** (rate limited)

OSM ecosystem

-   [**Overpass turbo**](https://overpass-turbo.eu/) web service for rapid development and testing of OSM queries
-   [**osm2pgsql**](https://osm2pgsql.org/) for importing the data into a PostGIS database
-   [**www.openstreetmap.org**](https://www.openstreetmap.org/)

```{r eval=FALSE}
library(osmdata)
parks = opq(bbox = "leeds uk") |> 
  add_osm_feature(key = "leisure", value = "park") |> 
  osmdata_sf()
str(parks)
```

```{r eval=FALSE}
abq_parks = opq(bbox = "albuquerque us") |> 
  add_osm_feature(key = "leisure", value = "park") |> 
  osmdata_sf()
str(abq_parks)
```

Packages with datasets, eg. **spData**, **spDataLarge**

```{r}
world2 <- spData::world
world3 <- read_sf(system.file("shapes/world.gpkg", package = "spData"))
```

## Geocoding

Transforming an address to it's coordinates **tidygeocoder**

```{r}
library(tidygeocoder)
geo_df <- data.frame(address = "6119 Mustang Ln NW, Albuquerque, NM 87120, US")
geo_df <- geocode(geo_df, address, method = "osm")
geo_df
```

# Geographic metadata

Geographic metadata are a cornerstone of geographic information management, used to describe datasets, data structures and services. They help make datasets FAIR (Findable, Accessible, Interoperable, Reusable) and are defined by the ISO/OGC standards, in particular the ISO 19115 standard and underlying schemas. These standards are widely used within spatial data infrastructures, handled through metadata catalogs.

Geographic metadata can be managed with **geometa**, a package that allows writing, reading and validating geographic metadata according to the ISO/OGC standards.

```{r}
library(geometa)
```

Create, fill, validate, encode, save

```{r eval=FALSE}
library(geometa)
# create a metadata
md = ISOMetadata$new()
#... fill the metadata 'md' object
# validate metadata
md$validate()
# XML representation of the ISOMetadata
xml = md$encode()
# save metadata
md$save("my_metadata.xml")
# read a metadata from an XML file
md = readISO19139("my_metadata.xml")
```

# Geographic web services

The Open Geospatial Consortium (OGC) has created a number of standard specifications for web services (collectively known as OWS, which is short for OGC Web Services).

-   Vector data can be accessed with the Web Feature Service (WFS)
-   grid/imagery can be accessed with the Web Coverage Service (WCS)
-   Map image representations, such as tiles, can be accessed with the Web Map Service (WMS) or the Web Map Tile Service (WMTS)
-   Metadata is also covered by means of the Catalogue Service for the Web (CSW)
-   Standard processing is handled through the Web Processing Service (WPS) or the the Web Coverage Processing Service (WCPS).

Various open-source projects have adopted these protocols, such as 

- [GeoServer](https://geoserver.org/), [MapServer](https://mapserver.org/) for data handling
- [GeoNetwork](https://geonetwork-opensource.org/) and [PyCSW](https://pycsw.org/) for metadata handling, leading to standardization of queries
- Integrated tools for Spatial Data Infrastructures (SDI), such as [GeoNode](https://geonode.org/), [GeOrchestra](https://www.georchestra.org/) or [Examind](https://www.examind.com/)

There are many requests that can be made to a OWS service. Below examples illustrate how some requests can be made directly with httr or more straightforward with the ows4R package (OGC Web-Services for R).

Let’s start with examples using the httr package, which can be useful for understanding how web services work. One of the most fundamental requests is getCapabilities, demonstrated with httr functions GET() and modify_url() below. The following code chunk demonstrates how API queries can be constructed and dispatched, in this case to discover the capabilities of a service run by the Fisheries and Aquaculture Division of the Food and Agriculture Organization of the United Nations (UN-FAO).

```{r}
library(httr)
base_url <- "https://www.fao.org"
endpoint <- "/fishery/geoserver/wfs"
q <- list(request = "GetCapabilities")
res <- GET(url = modify_url(base_url, path = endpoint),
           query = q)
res$url
```

```{r}
txt <- content(res, "text")
xml <- xml2::read_xml(txt)
xml
```

Available names differ depending on the accessed web feature service. One can extract them programmatically using web technologies (Nolan and Lang 2014) or scrolling manually through the contents of the GetCapabilities output in a browser.

```{r}
library(sf)
sf::sf_use_s2(FALSE)
qf <- list(request = "GetFeature",
           typeName = "fifao:FAO_MAJOR")
file <- tempfile(fileext = ".gml")
GET(url = base_url, path = endpoint,
    query = qf, write_disk(file))
fao_areas <- read_sf(file)
fao_areas
```

>In order to keep geometry validity along the data access chain, and since standards and underlying open-source server solutions (such as GeoServer) have been built on the Simple Features access, it is important to deactivate the new default behavior introduced in sf, and do not to use the S2 geometry model at data access time. 

Based on the above example, the code below show how to perform `getCapabilities` and `getFeatures` operations with the __ows4R__ package.
The ows4R package relies on the principle of clients. To interact with an OWS service (such as WFS), a client is created as follows:

```{r}
library(ows4R)
WFS <- WFSClient$new(
  url = "https://www.fao.org/fishery/geoserver/wfs",
  serviceVersion = "1.0.0",
  logger = "INFO"
)
```

```{r}
caps <- WFS$getCapabilities()
features <- WFS$getFeatures("fifao:FAO_MAJOR")
```

```{r}
caps
```

```{r}
features
```

# Visual outputs

```{r}
png(filename = "../images/lifeExp.png",
    width = 500, height = 350)
plot(world["lifeExp"])
dev.off()
```

Additionally, several graphic packages provide their own functions to save a graphical output. For example, the tmap package has the tmap_save() function. You can save a tmap object to different graphic formats or an HTML file by specifying the object name and a file path to a new file.


```{r}
library(tmap)
tmap_obj <- tm_shape(world) +  tm_polygons(col = "lifeExp")
tmap_save(tmap_obj, filename = "../images/lifeExp_tmap.png")
```


On the other hand, you can save interactive maps created in the mapview package as an HTML file or image using the mapshot2() function:

```{r}
library(mapview)
mapview_obj <- mapview(world, zcol = "lifeExp", legend = TRUE)
mapshot2(mapview_obj, file = "../images/my_interactive_map.html")
```

```{r}
mapshot2(mapview_obj, file = "my_interactive_map.html")
```

